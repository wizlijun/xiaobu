# 半自动 AI 协作研究与学习的实践方法

在 AI 工具泛滥的当下，我没有选择 Manus、NotebookLLM 这类一站式方案，而是搭建了一套半自动的协作流程。原因很简单：我希望对信息源和 AI 摘要的上下文保持控制权。这篇文章分享我如何通过工具选择、自动化脚本和人工判断相结合，在研究和学习中达到满意的效果。

## 用最好的模型

工具链的基础是选择当前能力最强的模型：

- **Claude Code Sonnet 4.5**：用于代码编写和复杂推理任务
- **GPT-5 Think**：用于深度思考和联网搜索推荐
- **Gemini Pro 2.5 1M 上下文**：用于处理大规模文本的摘要，充分利用其 1M 上下文窗口能力

## 自动化脚本处理

使用 Claude Code 或 Cursor 等 AI coding 工具写脚本，逐步把手动处理部分自动化。

### 文档与音视频处理

如文档处理、音视频处理等，都转换为大模型输入友好的 Markdown 文件。这样可以统一信息格式，方便后续的批量处理和摘要提取。

## 自定义 Commands 实现自动化

使用 Claude Code 的自定义 commands，做一些大模型自动化的功能。

### 实验到固化的流程

通过 Cursor 或 Claude Code 的交互对话，实验出效果后，把常用的写成 commands。例如生成博客文章、发布博客等操作，都可以固化为可重复执行的命令。

## 关键的人工参与环节

### 信息源的信任判断

有一个信息源信任判断问题，书是我选的。根据知名度、朋友的信任背书，也参考了 GPT-5 给的推荐。而不只是公共资源（容易平庸）。对于专业领域、有深度的内容，可能不能依赖于公开搜索。

### 源头信息的摘要

每次接近 1M 的上下文窗口，使用了 Gemini Pro 2.5 的 1M 窗口。源头信息包括：

- **原版著作**：书籍纯文本一般在 1M 以内，使用脚本和开源工具转换。顺便做了书籍翻译。
- **论文、行业报告**：顺便翻译和摘要。
- **原始访谈、演讲的视频、播客**：YouTube 语音识别导出的脚本，一般也在 1M 以内。顺便也做了 AI 音频译制。
- **无法下载的会议、直播等内容**：使用录音卡，语音转换，注意声纹识别。一般 1 个小时的会议，字幕也在 1M 以内。
- **微信群聊**：使用 chatbot 的 MCP，分析有价值群聊里的关键内容。
- **认识的人写的有深度和有见解的博客**：一般在公众号或博客中。
- **使用 ChatGPT GPT-5 DeepThink 联网搜索推荐的一些互联网资源**：这个跟 ChatGPT 对话时可以获得。

### 摘要过程中的目标导向

每一个资源的摘要过程中，始终告诉模型最终的目标。我要写一篇关于什么的文章，但不事先给结论。如果不翻译为中文，消耗不了太多 token。

### 层层摘要而非 RAG

非 RAG，而是层层摘要，类似 Claude Code 的 compact，压缩信息。每一次的结果都要确认一下，容易遗漏。这些副产品可能是书籍摘要、视频博客摘要。针对你感兴趣的目标和方向去摘要。

### AI 生成时的同步阅读

AI 生成的过程中，我都在快速阅读概览，然后做大纲笔记，把我认为重要的写下来。越重要的可能就越详细。

### 价值观排序

告诉他你认为哪些重要，给他价值观排序。例如最后摘要生成时，我一定会再告诉他我的笔记的摘要，是我认为重要的要点。

## 人工参与的原则与注意事项

这样人工参与，确保了可信的源头、个人的价值判断、自始至终的输出目标。但也要有基本的注意：

### 基本科学素养

不观点先行，不自证。虽然自己不能完全做到，但必须让 AI 做到。

### 开放式对话

关注 AI 给出的反常信息，可能是自己的知识盲区。避免自负。

### 聚焦擅长领域

只研究自己擅长或正在深入的领域，避免泛泛。以实践和作品为动力，去学习研究。多行动。

### 追求深度与非大众洞见

追求领域知识和经验的深度，挖掘非大众但深入的洞见，注重社区传播的内容。远离流量，流量内容只关注其中引用的源头信息。

### 信任背书

交朋友，请教领域专家，以信任增强信息价值。

### 有需求才输出

所有 token 效果（让 AI 做的输出），务必读完，也就是说有需求才去做，要解决自己明确的问题。不要为了分享或别人看而去消耗。会形成囤积癖，主要是会产生很多不可判断的垃圾信息，导致对知识库失去信任。

## 最终输出

最终输出的东西，起码可以代表自己的观点。

- 研究的过程，也是学习的过程
- 过程中也可以输出很多副产物