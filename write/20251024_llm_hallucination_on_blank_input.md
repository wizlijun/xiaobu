# LLM 在空白输入时的幻觉问题

## 背景

在日常使用 LLM 的过程中，我和团队成员都注意到一个共性问题：当输入内容为空白或信息量极少时，LLM 的幻觉现象会格外明显。本文整理了几个实际场景中遇到的典型案例，以及对应的应对思路。

## 几个典型场景

### 代码审查中的"假 bug"

同事在使用 LLM 辅助 Coding 时发现，即使代码没有明显 bug，LLM 也会幻觉出一些问题并给出修复建议。这种"无中生有"的现象在输入信息不足时尤为突出。

### 空白文档的"续写"陷阱

我的使用经验是：当提供的文档为空白时，LLM 硬是生成一些像模像样的内容。反而是给他内容太多了，他会遗漏不少内容。因此幻觉往往发生在无中生有时，此时更像是在触发大模型的续写特性。

### 视频翻译中的静音幻觉

最近做长视频翻译时，当音频静音时，whisper 这类基于 LLM 技术的模型会在空白时段生成一些莫名其妙的文字，往往是常见的"谢谢""就这样"之类的。

因为没有对应的音色，后续的 TTS 引擎也会用默认的声音输出，特别滑稽：B 站的 indextts 会用动漫妹子的夹子音在严肃的会议视频里插上两句。

#### 解决方案：VAD 与 whisper 参数

朋友们建议使用 VAD 去掉无人声部分。

**VAD** 是 **Voice Activity Detection（语音活动检测）** 的缩写，是一种用来判断语音信号中是否存在人声的技术。它是语音处理、语音识别、语音通信等系统中的一个基础模块。

whisper 的参数中也有对应的参数和使用建议，避免这种幻觉。我通过问 ChatGPT 找到了参数，并解决了一些问题，但还是会有一些幻觉，VAD 可能是有必要的。

### OCR 场景的类似问题

以此类推，那些 LLM 生成的 OCR 模型方案，估计在处理空白的图片时，也会生成幻觉 OCR，会识别出莫名其妙的常见语。

## 技术原理与应对

这些问题是 LLM 从训练实现中的技术原理带来的。我们熟知以后，就可以避免。

同样，当你给他的文章没有知识可洞察时，让他去列出知识，他就会生成一些幻觉知识和见解，有可能误导你。

当然，读者对原始内容是否有洞见有观点的判断力都没有时，LLM 幻觉生成的是有可能让他相信的。当上当受骗以后，就会赖 LLM 幻觉骗了他。问题在谁？

## 小结

空白输入是 LLM 幻觉的高发场景。无论是代码审查、文档生成、语音识别还是图像 OCR，当输入信息不足时，模型会倾向于"续写"常见内容。了解这一特性后，我们可以通过预处理（如 VAD）、调整模型参数或提高输入质量来减少幻觉的影响。同时，保持对输出结果的批判性审视也是必要的。
