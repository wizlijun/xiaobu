# AI SDK 调试实录：复杂度陷阱与应对

最近在调试 SDK 访问时，大部分时间都花在了看日志、定位问题、让 AI 修改代码的循环上。因为不直接改代码，只能通过不断检查 logs 找出问题所在，然后指出具体位置让 AI 去修改。这个过程暴露出一些配置驱动架构下容易踩的坑。

## 配置错误导致的意外输出

在一次调试中，发现生成的是 JSON 而不是预期的 PNG 图片。排查后发现是自己在 Markdown 配置中写错了，让 LLM 生成了错误的格式。

这里有个有趣的现象：agent 遵循指令反而太好了。它严格按照配置文件的要求执行，即使配置本身有误，也会忠实地生成错误的结果。

## Pydantic 模型字段缺失问题

更深层的问题出现在 `app/models/agent.py` 中。`AgentStep` 模型缺少 `execution_type` 和 `model` 字段定义。虽然 `agents/story.yml` 配置文件中设置了这些字段，但因为 Pydantic 模型中没有定义，这些值在加载 YAML 时被直接忽略了。

### 复杂度叠加的连锁反应

每引入一个组件，复杂度就会增加一部分。一旦修改配置不完整，就有可能导致功能失效。

### 问题根源

本质上，这相当于 AI 自己写了一个根据配置执行的解析器，但我没有进行设计和检查。在增加新的配置项后，AI 没有同步更新解析器逻辑。

### 反思

随着配置复杂度、调用组件的复杂度增加，无论是个人疏忽还是 AI 疏忽，都会导致一些意想不到的问题出现。这时就需要 debug。

AI debug 也是不断尝试，人 debug 也是不断尝试，本质上没有区别。

#### 怎么降低复杂度？

- 好的习惯、文档、流程
- 结构化约定

## 工具磨合期的效率问题

新工具在磨合初期，可能确实没有什么效率可言。但从另一个角度看，人会愉快很多——想法表达完了，细枝末节的事情不需要自己亲手做了。

## HTTPS 超时与架构调整

遇到了 HTTPS 超时问题，系统级默认是 60s。

### 需要的改进方向

- 需要改为异步等待、查询的策略
- SSE 流式、异步方式需要投入设计，避免 token 浪费
