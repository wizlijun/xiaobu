<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Agent 的有效上下文工程</title>
    <style>
        body {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #fff;
        }
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            margin-top: 20px;
        }
        h2 {
            color: #34495e;
            margin-top: 30px;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }
        h3 {
            color: #34495e;
            margin-top: 25px;
        }
        .intro {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            margin: 20px 0;
            border-left: 4px solid #3498db;
        }
        .highlight {
            background-color: #fff3cd;
            padding: 15px;
            border-radius: 5px;
            border-left: 4px solid #ffc107;
            margin: 20px 0;
        }
        .key-point {
            background-color: #f1f8ff;
            padding: 15px;
            margin: 15px 0;
            border-radius: 8px;
            border-left: 4px solid #0366d6;
        }
        code {
            background-color: #f4f4f4;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
        }
        pre {
            background-color: #f8f8f8;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            border: 1px solid #ddd;
        }
        ul, ol {
            margin: 15px 0;
            padding-left: 30px;
        }
        li {
            margin: 8px 0;
        }
        .acknowledgements {
            background-color: #f6f8fa;
            padding: 15px;
            margin: 20px 0;
            border-radius: 8px;
            font-size: 0.9em;
            color: #586069;
        }
    </style>
</head>
<body>
    <h1>AI Agent 的有效上下文工程</h1>

    <div class="intro">
        <p>上下文（Context）是 AI Agent 的关键但有限的资源。本文探讨如何有效地策划和管理驱动 Agent 的上下文。</p>

        <p>在过去几年里，提示工程（Prompt Engineering）一直是应用 AI 领域关注的焦点，而现在一个新术语逐渐浮现：上下文工程（Context Engineering）。使用语言模型构建应用正在从"为提示词找到合适的措辞"转向回答一个更广泛的问题："什么样的上下文配置最有可能产生我们期望的模型行为?"</p>

        <p>上下文是指在大语言模型（LLM）采样时包含的 token 集合。当前的工程问题是在 LLM 固有约束下优化这些 token 的效用，以持续实现期望的结果。有效驾驭 LLM 往往需要"在上下文中思考"，也就是说：考虑 LLM 在任何给定时间可用的整体状态，以及该状态可能产生的潜在行为。</p>
    </div>

    <h2>上下文工程 vs 提示工程</h2>

    <p>在 Anthropic，我们将上下文工程视为提示工程的自然演进。提示工程是指为了达到最优结果而编写和组织 LLM 指令的方法。上下文工程则是指在 LLM 推理过程中策划和维护最优 token 集（信息）的一系列策略，包括所有可能进入上下文的提示词之外的其他信息。</p>

    <p>在 LLM 工程的早期阶段，提示词是 AI 工程工作的最大组成部分，因为除了日常聊天交互之外，大多数用例都需要针对单次分类或文本生成任务优化的提示词。顾名思义，提示工程的主要重点是如何编写有效的提示词，尤其是系统提示词。然而，当我们转向构建能够进行多轮推理和更长时间跨度操作的更强大 Agent 时，我们需要管理整个上下文状态的策略（系统指令、工具、Model Context Protocol (MCP)、外部数据、消息历史等）。</p>

    <p>在循环中运行的 Agent 会生成越来越多可能与下一轮推理相关的数据，这些信息必须被周期性地精炼。上下文工程是从不断演变的可能信息宇宙中策划哪些内容将进入有限上下文窗口的艺术和科学。</p>

    <div class="key-point">
        <p><strong>关键区别：</strong>与编写提示词这一离散任务相比，上下文工程是迭代的，每次我们决定向模型传递什么内容时都会发生策划阶段。</p>
    </div>

    <h2>为什么上下文工程对构建强大 Agent 很重要</h2>

    <p>尽管 LLM 速度快且能够管理越来越大量的数据，我们观察到 LLM 像人类一样，会在某个点上失去焦点或感到困惑。关于 needle-in-a-haystack 风格基准测试的研究揭示了"上下文腐化"（context rot）的概念：随着上下文窗口中 token 数量的增加，模型从该上下文中准确召回信息的能力会下降。</p>

    <p>虽然有些模型表现出更温和的性能退化，但这一特征在所有模型中都会出现。因此，上下文必须被视为一种边际收益递减的有限资源。就像人类的工作记忆容量有限一样，LLM 也有一个"注意力预算"，在解析大量上下文时会消耗这个预算。引入的每个新 token 都会在一定程度上耗尽这个预算，从而增加了仔细策划 LLM 可用 token 的必要性。</p>

    <div class="highlight">
        <p><strong>架构约束：</strong>这种注意力稀缺性源于 LLM 的架构约束。LLM 基于 Transformer 架构，该架构使每个 token 都能关注整个上下文中的其他所有 token。这导致 n 个 token 产生 n² 个成对关系。</p>
    </div>

    <p>随着上下文长度的增加，模型捕获这些成对关系的能力被拉伸得很薄，在上下文大小和注意力焦点之间产生了自然张力。此外，模型从训练数据分布中发展其注意力模式，其中较短序列通常比较长序列更常见。这意味着模型对上下文范围的依赖关系经验较少，专用参数也较少。</p>

    <p>诸如位置编码插值之类的技术允许模型通过将它们调整到原始训练的较小上下文来处理更长的序列，尽管在 token 位置理解上会有一些退化。这些因素产生了性能梯度而非硬断崖：模型在较长上下文中仍然非常强大，但与在较短上下文上的性能相比，在信息检索和长程推理方面可能表现出精度降低。</p>

    <p>这些现实意味着周到的上下文工程对于构建强大 Agent 至关重要。</p>

    <h2>有效上下文的剖析</h2>

    <p>鉴于 LLM 受到有限注意力预算的约束，良好的上下文工程意味着找到最小的高信号 token 集合，以最大化某些期望结果的可能性。实践这一原则说起来容易做起来难，但在下一节中，我们概述了这一指导原则在上下文不同组成部分中的实际意义。</p>

    <h3>系统提示词</h3>

    <p>系统提示词应该极其清晰，使用简单、直接的语言，以适合 Agent 的高度呈现想法。正确的高度是两种常见失败模式之间的黄金地带。在一个极端，我们看到工程师在提示词中硬编码复杂、脆弱的逻辑以引发精确的 Agent 行为。这种方法会产生脆弱性并随着时间推移增加维护复杂性。在另一个极端，工程师有时提供模糊的高级指导，无法为期望输出提供具体信号或错误地假设共享上下文。最佳高度在两者之间取得平衡：既足够具体以有效指导行为，又足够灵活以为模型提供强大的启发式来指导行为。</p>

    <p>我们建议将提示词组织成不同的部分（如 <code>&lt;background_information&gt;</code>、<code>&lt;instructions&gt;</code>、<code>## Tool guidance</code>、<code>## Output description</code> 等），并使用 XML 标记或 Markdown 标题等技术来划分这些部分，尽管随着模型变得更加强大，提示词的确切格式可能变得不那么重要。</p>

    <p>无论您如何决定构建系统提示词，都应该追求完全概述预期行为的最小信息集。（请注意，最小并不一定意味着短；您仍然需要预先提供足够的信息以确保 Agent 遵守期望的行为。）最好先使用最佳可用模型测试最小提示词，看看它在您的任务上表现如何，然后根据初始测试期间发现的失败模式添加清晰的指令和示例以改进性能。</p>

    <h3>工具</h3>

    <p>工具允许 Agent 与其环境交互并在工作时引入新的附加上下文。因为工具定义了 Agent 与其信息/操作空间之间的契约，所以工具促进效率极其重要，无论是通过返回 token 高效的信息还是通过鼓励高效的 Agent 行为。</p>

    <p>类似于设计良好代码库的函数，工具应该是自包含的、对错误健壮的，并且在预期用途方面极其清晰。输入参数同样应该是描述性的、明确的，并且发挥模型的固有优势。</p>

    <div class="highlight">
        <p><strong>常见失败模式：</strong>我们看到的最常见失败模式之一是臃肿的工具集，它们涵盖太多功能或导致关于使用哪个工具的模糊决策点。如果人类工程师无法明确说出在特定情况下应该使用哪个工具，就不能期望 AI Agent 做得更好。</p>
    </div>

    <h3>示例</h3>

    <p>提供示例，也称为 few-shot 提示，是我们继续强烈建议的一个众所周知的最佳实践。然而，团队经常会将一长串边缘案例塞进提示词中，试图阐明 LLM 应该遵循的每条可能规则来完成特定任务。我们不建议这样做。相反，我们建议策划一组多样化的规范示例，有效地展示 Agent 的预期行为。对于 LLM 来说，示例就是价值千言的"图片"。</p>

    <p>我们在上下文不同组件（系统提示词、工具、示例、消息历史等）上的总体指导是要深思熟虑，保持上下文信息丰富但紧凑。现在让我们深入探讨在运行时动态检索上下文。</p>

    <h2>上下文检索和 Agent 搜索</h2>

    <p>在构建有效的 AI Agent 方面，我们强调了基于 LLM 的工作流和 Agent 之间的区别。自从我们写那篇文章以来，我们已经倾向于一个简单的 Agent 定义：在循环中自主使用工具的 LLM。</p>

    <p>与我们的客户一起工作，我们看到该领域正在向这个简单范式收敛。随着底层模型变得更加强大，Agent 的自主程度可以扩展：更智能的模型允许 Agent 独立地导航微妙的问题空间并从错误中恢复。</p>

    <div class="key-point">
        <p><strong>"即时"上下文策略：</strong>我们现在看到工程师在思考如何为 Agent 设计上下文方面发生了转变。今天，许多 AI 原生应用程序采用某种形式的基于嵌入的推理前检索，以为 Agent 提供重要的上下文进行推理。随着该领域向更 Agent 化的方法过渡，我们越来越多地看到团队使用"即时"（just in time）上下文策略来增强这些检索系统。</p>
    </div>

    <p>采用"即时"方法构建的 Agent 不是预先处理所有相关数据，而是维护轻量级标识符（文件路径、存储的查询、Web 链接等），并使用这些引用在运行时使用工具动态加载数据到上下文中。Anthropic 的 Agent 编码解决方案 Claude Code 使用这种方法对大型数据库执行复杂的数据分析。模型可以编写有针对性的查询、存储结果，并利用 <code>head</code> 和 <code>tail</code> 等 Bash 命令分析大量数据，而无需将完整的数据对象加载到上下文中。这种方法反映了人类认知：我们通常不会记住整个信息语料库，而是引入外部组织和索引系统，如文件系统、收件箱和书签，以按需检索相关信息。</p>

    <p>除了存储效率之外，这些引用的元数据提供了一种有效改进行为的机制，无论是明确提供的还是直觉的。对于在文件系统中操作的 Agent，<code>tests</code> 文件夹中名为 <code>test_utils.py</code> 的文件意味着与位于 <code>src/core_logic/</code> 中同名文件不同的目的。文件夹层次结构、命名约定和时间戳都提供了重要信号，帮助人类和 Agent 了解如何以及何时利用信息。</p>

    <p>让 Agent 自主导航和检索数据还启用了渐进式披露（progressive disclosure）——换句话说，允许 Agent 通过探索逐步发现相关上下文。每次交互都会产生为下一个决策提供信息的上下文：文件大小暗示复杂性；命名约定暗示目的；时间戳可以作为相关性的代理。Agent 可以逐层组装理解，仅维护工作记忆中必要的内容，并利用笔记策略实现额外的持久性。这种自我管理的上下文窗口使 Agent 专注于相关子集，而不是淹没在详尽但可能无关的信息中。</p>

    <div class="highlight">
        <p><strong>权衡考虑：</strong>当然，有一个权衡：运行时探索比检索预先计算的数据慢。不仅如此，还需要有见地和深思熟虑的工程来确保 LLM 拥有有效导航其信息景观的正确工具和启发式。没有适当的指导，Agent 可能会通过误用工具、追逐死胡同或无法识别关键信息而浪费上下文。</p>
    </div>

    <p>在某些设置中，最有效的 Agent 可能采用混合策略，预先检索一些数据以提高速度，并根据其自由裁量权进行进一步的自主探索。"正确"自主程度的决策边界取决于任务。Claude Code 是一个采用这种混合模型的 Agent：<code>CLAUDE.md</code> 文件被简单地预先放入上下文，而像 <code>glob</code> 和 <code>grep</code> 这样的原语允许它导航其环境并即时检索文件，有效地绕过陈旧索引和复杂语法树的问题。</p>

    <p>混合策略可能更适合内容动态性较低的上下文，例如法律或金融工作。随着模型能力的提高，Agent 设计将趋向于让智能模型智能地行动，人工策划逐渐减少。鉴于该领域的快速进步，"做最简单有效的事情"可能仍然是我们对在 Claude 之上构建 Agent 的团队的最佳建议。</p>

    <h2>长期任务的上下文工程</h2>

    <p>长期任务要求 Agent 在 token 计数超过 LLM 上下文窗口的动作序列中维持连贯性、上下文和目标导向行为。对于跨越数十分钟到数小时连续工作的任务，如大型代码库迁移或综合研究项目，Agent 需要专门的技术来解决上下文窗口大小限制。</p>

    <p>等待更大的上下文窗口可能看起来是一个明显的策略。但在可预见的未来，所有大小的上下文窗口都可能受到上下文污染和信息相关性问题的影响——至少在需要最强 Agent 性能的情况下是这样。为了使 Agent 能够在扩展的时间范围内有效工作，我们开发了一些直接解决这些上下文污染约束的技术：压缩（compaction）、结构化笔记和多 Agent 架构。</p>

    <h3>压缩</h3>

    <p>压缩是将接近上下文窗口限制的对话进行总结，并用摘要重新启动新上下文窗口的实践。压缩通常是上下文工程中推动更好长期连贯性的第一个杠杆。其核心是，压缩以高保真度提炼上下文窗口的内容，使 Agent 能够以最小的性能下降继续工作。</p>

    <p>例如，在 Claude Code 中，我们通过将消息历史传递给模型来总结和压缩最关键的细节来实现这一点。模型保留架构决策、未解决的错误和实现细节，同时丢弃冗余的工具输出或消息。然后 Agent 可以使用这个压缩上下文加上最近访问的五个文件继续工作。用户获得了连续性，而不必担心上下文窗口限制。</p>

    <p>压缩的艺术在于选择保留什么与丢弃什么，因为过于激进的压缩可能导致丢失微妙但关键的上下文，其重要性只在后来才变得明显。对于实现压缩系统的工程师，我们建议在复杂的 Agent 跟踪上仔细调整您的提示词。首先最大化召回率以确保您的压缩提示词捕获跟踪中的每一条相关信息，然后通过消除多余内容来迭代提高精度。</p>

    <p>一个容易处理的多余内容示例是清除工具调用和结果——一旦工具在消息历史深处被调用，为什么 Agent 需要再次看到原始结果？最安全、最轻量级的压缩形式之一是工具结果清除，最近作为 Claude Developer Platform 上的一项功能推出。</p>

    <h3>结构化笔记</h3>

    <p>结构化笔记或 Agent 记忆是一种技术，Agent 定期将笔记写入上下文窗口外的持久内存中。这些笔记稍后会被拉回到上下文窗口中。</p>

    <p>这种策略以最小的开销提供持久内存。就像 Claude Code 创建待办事项列表，或您的自定义 Agent 维护 <code>NOTES.md</code> 文件一样，这种简单的模式允许 Agent 跨复杂任务跟踪进度，维护原本会在数十次工具调用中丢失的关键上下文和依赖关系。</p>

    <div class="key-point">
        <p><strong>实例：Claude 玩 Pokémon</strong></p>
        <p>Claude 玩 Pokémon 展示了记忆如何在非编码领域转变 Agent 能力。Agent 在数千个游戏步骤中维护精确的统计——跟踪目标，如"在过去的 1,234 步中，我一直在 Route 1 训练我的 Pokémon，Pikachu 已经获得了 8 个等级，目标是 10 个"。没有任何关于记忆结构的提示，它开发了探索区域的地图，记住了它解锁了哪些关键成就，并维护了战斗策略的战略笔记，帮助它学习哪些攻击对不同对手最有效。</p>
    </div>

    <p>在上下文重置之后，Agent 读取自己的笔记并继续多小时的训练序列或地牢探索。这种跨摘要步骤的连贯性使得长期策略成为可能，如果只将所有信息保留在 LLM 的上下文窗口中，这将是不可能的。</p>

    <p>作为 Sonnet 4.5 发布的一部分，我们在 Claude Developer Platform 上发布了公开测试版的记忆工具，通过基于文件的系统更容易地存储和查询上下文窗口外的信息。这允许 Agent 随着时间推移建立知识库，跨会话维护项目状态，并引用以前的工作而不将所有内容保留在上下文中。</p>

    <h3>子 Agent 架构</h3>

    <p>子 Agent 架构提供了解决上下文限制的另一种方法。与其一个 Agent 尝试维护整个项目的状态，专门的子 Agent 可以使用干净的上下文窗口处理集中的任务。主 Agent 使用高级计划进行协调，而子 Agent 执行深入的技术工作或使用工具查找相关信息。每个子 Agent 可能会进行广泛的探索，使用数万个 token 或更多，但只返回其工作的浓缩摘要（通常为 1,000-2,000 个 token）。</p>

    <p>这种方法实现了清晰的关注点分离——详细的搜索上下文隔离在子 Agent 内，而主 Agent 专注于综合和分析结果。这种模式在复杂研究任务上显示出比单 Agent 系统大幅改进。</p>

    <p>这些方法之间的选择取决于任务特征。例如：</p>

    <ul>
        <li><strong>压缩</strong>为需要大量来回的任务维护对话流</li>
        <li><strong>笔记</strong>在具有明确里程碑的迭代开发中表现出色</li>
        <li><strong>多 Agent 架构</strong>处理复杂的研究和分析，其中并行探索带来回报</li>
    </ul>

    <p>即使模型继续改进，在扩展交互中维持连贯性的挑战仍将是构建更有效 Agent 的核心。</p>

    <h2>结论</h2>

    <p>上下文工程代表了我们如何使用 LLM 构建应用的根本转变。随着模型变得更加强大，挑战不仅仅是制作完美的提示词——而是在每一步深思熟虑地策划哪些信息进入模型有限的注意力预算。无论您是为长期任务实施压缩、设计 token 高效的工具，还是使 Agent 能够即时探索其环境，指导原则保持不变：找到最小的高信号 token 集合，以最大化期望结果的可能性。</p>

    <p>我们概述的技术将随着模型的改进而继续发展。我们已经看到更智能的模型需要更少的规定性工程，允许 Agent 以更大的自主性运行。但即使能力扩展，将上下文视为宝贵的有限资源仍将是构建可靠、有效 Agent 的核心。</p>

    <p>今天就在 Claude Developer Platform 开始上下文工程，并通过我们的记忆和上下文管理 cookbook 访问有用的提示和最佳实践。</p>

    <div class="acknowledgements">
        <p><strong>致谢</strong></p>
        <p>本文由 Anthropic 应用 AI 团队撰写：Prithvi Rajasekaran、Ethan Dixon、Carly Ryan 和 Jeremy Hadfield，团队成员 Rafi Ayub、Hannah Moran、Cal Rueb 和 Connor Jennings 做出了贡献。特别感谢 Molly Vorwerck、Stuart Ritchie 和 Maggie Vo 的支持。</p>
    </div>
</body>
</html>
