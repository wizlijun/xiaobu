<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI论文探索之旅：全景解析与发展史</title>
    <style>
        /* --- Global Styles & Variables --- */
        :root {
            --primary-color: #3498db;
            --secondary-color: #ecf0f1;
            --text-color: #34495e;
            --bg-color: #f8f9fa;
            --card-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
            --highlight-bg: #e8f4fd;
            --fact-color: #27ae60;
            --opinion-color: #8e44ad;
            --quote-color: #7f8c8d;
        }

        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@300;400;500;700&display=swap');

        body {
            font-family: 'Noto Sans SC', sans-serif;
            background-color: var(--bg-color);
            color: var(--text-color);
            line-height: 1.8;
            margin: 0;
            padding: 0;
        }

        .page-wrapper {
            max-width: 1200px;
            margin: 40px auto;
            padding: 20px;
        }
        
        .main-header {
            text-align: center;
            margin-bottom: 50px;
        }

        .main-header h1 {
            color: var(--primary-color);
            font-weight: 700;
            font-size: 2.8em;
            margin-bottom: 10px;
        }

        .main-header p {
            font-size: 1.2em;
            color: #7f8c8d;
        }
        
        .section-container {
            background: #ffffff;
            padding: 25px 40px;
            border-radius: 12px;
            box-shadow: var(--card-shadow);
            margin-bottom: 60px;
        }

        .section-container h2 {
            font-size: 2.2em;
            text-align: center;
            color: var(--primary-color);
            border-bottom: 3px solid var(--secondary-color);
            padding-bottom: 15px;
            margin-bottom: 30px;
        }

        /* --- Part 1: Insights & Digest Styles --- */
        .speaker-profile {
            background-color: var(--secondary-color);
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05) inset;
        }
        .speaker-profile h3 { margin-top: 0; color: var(--text-color); font-size: 1.4em; border-bottom: none; }
        .speaker-profile p { margin: 5px 0; }
        
        .collapsible {
            background-color: var(--primary-color);
            color: white;
            cursor: pointer;
            padding: 18px;
            width: 100%;
            border: none;
            text-align: left;
            outline: none;
            font-size: 18px;
            border-radius: 8px;
            transition: background-color 0.3s;
            margin-bottom: 10px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-weight: 500;
        }
        .collapsible:hover { background-color: #2980b9; }
        .collapsible .arrow { transition: transform 0.3s; }
        .collapsible.active .arrow { transform: rotate(90deg); }
        
        .content {
            padding: 0 18px;
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.4s ease-out;
            background-color: #fdfdfd;
            border-radius: 8px;
            border: 1px solid var(--secondary-color);
        }
        .content-inner { padding: 20px; }
        .highlight { background-color: var(--highlight-bg); padding: 2px 6px; border-radius: 4px; font-weight: bold; }
        .fact { color: var(--fact-color); font-weight: bold; }
        .opinion { color: var(--opinion-color); font-style: italic; }
        .quote { border-left: 4px solid var(--quote-color); padding-left: 15px; margin: 15px 0; color: var(--quote-color); font-size: 1.1em; }
        .section-container ul { list-style-type: disc; padding-left: 25px; }
        .section-container ul li { margin-bottom: 12px; }

        /* --- Part 2: Timeline Styles --- */
        .theme-section {
            background: #ffffff;
            padding: 25px 40px;
            border-radius: 12px;
            box-shadow: var(--card-shadow);
            margin-bottom: 60px;
        }
        .theme-section h2 {
            font-size: 2.2em;
            text-align: center;
            color: var(--primary-color);
            border-bottom: 3px solid var(--secondary-color);
            padding-bottom: 15px;
            margin-bottom: 30px;
        }
        .timeline-wrapper { 
            position: relative; 
            width: 100%; 
            overflow-x: auto; 
            overflow-y: hidden; 
            padding: 80px 0; 
            white-space: nowrap; 
            -webkit-overflow-scrolling: touch; 
        }
        .timeline-wrapper::-webkit-scrollbar { height: 8px; }
        .timeline-wrapper::-webkit-scrollbar-track { background: var(--secondary-color); border-radius: 4px; }
        .timeline-wrapper::-webkit-scrollbar-thumb { background: #ccc; border-radius: 4px; }
        .timeline-wrapper::-webkit-scrollbar-thumb:hover { background: #aaa; }
        .timeline { 
            display: inline-flex; 
            position: relative; 
            padding: 0 15px; 
            min-width: 100%; 
            height: 200px;
            align-items: center;
        }
        .timeline::before { 
            content: ''; 
            position: absolute; 
            top: 50%; 
            left: 0; 
            width: 100%; 
            height: 4px; 
            background: var(--secondary-color); 
            transform: translateY(-50%); 
            z-index: 0;
        }
        .timeline-item { 
            display: flex; 
            flex-direction: column; 
            align-items: center; 
            justify-content: center;
            position: relative; 
            margin: 0 40px; 
            min-width: 200px; 
            height: 100%;
        }
        .timeline-item .timeline-dot { 
            position: absolute; 
            top: 50%; 
            left: 50%; 
            width: 20px; 
            height: 20px; 
            background-color: #fff; 
            border: 4px solid var(--primary-color); 
            border-radius: 50%; 
            transform: translate(-50%, -50%); 
            z-index: 2; 
            transition: transform 0.3s ease; 
        }
        .timeline-item:hover .timeline-dot { 
            transform: translate(-50%, -50%) scale(1.2); 
        }
        .timeline-content { 
            padding: 15px; 
            background: #fff; 
            border-radius: 8px; 
            box-shadow: 0 2px 10px rgba(0,0,0,0.08); 
            border: 1px solid var(--secondary-color); 
            text-align: center; 
            white-space: normal; 
            cursor: pointer; 
            transition: transform 0.3s ease, box-shadow 0.3s ease; 
            width: 180px;
            position: absolute;
        }
        .timeline-item:nth-child(odd) .timeline-content { 
            bottom: 50%; 
            margin-bottom: 30px;
        }
        .timeline-item:nth-child(even) .timeline-content { 
            top: 50%; 
            margin-top: 30px;
        }
        .timeline-item:hover .timeline-content { 
            box-shadow: 0 6px 20px rgba(0,0,0,0.12); 
        }
        .timeline-item:hover:nth-child(odd) .timeline-content { 
            margin-bottom: 35px; 
        }
        .timeline-item:hover:nth-child(even) .timeline-content { 
            margin-top: 35px; 
        }
        .timeline-date { 
            font-size: 1.4em; 
            font-weight: 700; 
            color: var(--primary-color); 
        }
        .timeline-title { 
            font-size: 1.1em; 
            font-weight: 500; 
            margin: 8px 0; 
        }
        
        /* --- Shared Modal Styles --- */
        .modal { display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; overflow: auto; background-color: rgba(0,0,0,0.6); animation: fadeIn 0.3s; }
        .modal-content { background-color: #fefefe; margin: 10% auto; padding: 30px; border: 1px solid #888; width: 80%; max-width: 700px; border-radius: 10px; box-shadow: 0 5px 20px rgba(0,0,0,0.3); animation: slideIn 0.4s; }
        .close-btn { color: #aaa; float: right; font-size: 28px; font-weight: bold; cursor: pointer; }
        .close-btn:hover, .close-btn:focus { color: black; }
        #modal-year { font-size: 2em; font-weight: bold; color: var(--primary-color); }
        #modal-title { font-size: 1.5em; margin-top: 5px; margin-bottom: 20px; border-bottom: 2px solid var(--secondary-color); padding-bottom: 10px; }
        .modal-body p { margin-bottom: 15px; }
        .timeline-tag { display: inline-block; padding: 4px 10px; margin: 5px 5px 5px 0; border-radius: 15px; font-size: 0.8em; color: white; font-weight: 500; }
        
        @keyframes fadeIn { from {opacity: 0;} to {opacity: 1;} }
        @keyframes slideIn { from {transform: translateY(-50px); opacity: 0;} to {transform: translateY(0); opacity: 1;} }
        @media screen and (max-width: 768px) {
            .page-wrapper { padding: 10px; margin: 20px auto; }
            .main-header h1 { font-size: 2em; }
            .section-container { padding: 20px 15px; }
            .modal-content { width: 90%; margin: 20% auto; }
        }
    </style>
</head>
<body>

<div class="page-wrapper">
    <div class="main-header">
        <h1>AI论文探索之旅：全景解析</h1>
        <p>一份包含深度洞察与交互式发展史的完整访谈摘要</p>
    </div>

    <!-- ====== Part 1: Insights & Digest ====== -->
    <div class="section-container">
        <h2>学习心法与行业洞察</h2>
        <div class="speaker-profile">
            <h3>对话者</h3>
            <p><strong>谢青池 (Qingchi Xie):</strong> 美团光年之外产品负责人。非技术出身，但拥有计算机专业背景。在GPT浪潮后，出于强烈的好奇心和职业需要，用两年业余时间精读了超200篇AI核心论文，致力于探索AI的技术边界。</p>
        </div>

        <div class="insights-content">
            <button type="button" class="collapsible">
                <span>个人学习的“心法”与“方法论”</span>
                <span class="arrow">▶</span>
            </button>
            <div class="content">
                <div class="content-inner">
                    <ul>
                        <li><span class="fact">核心动机：</span><span class="opinion">作为产品经理，需要通过理解技术边界的变化来寻找产品的最优解。</span></li>
                        <li><span class="fact">学习方法：</span>
                            <ul>
                                <li><strong>用AI学习AI：</strong>这是他反复强调的核心方法。使用<span class="highlight">沉浸式翻译</span>克服语言障碍，用<span class="highlight">大模型</span>当老师，用<span class="highlight">可视化工具</span>辅助理解。</li>
                                <li><strong>建立体系：</strong>先重学数学基础，再通过体系化的视频教程建立宏观框架，最后才深入论文细节。</li>
                                <li><strong>追本溯源：</strong>不断追问“为什么”，理解技术演进的前因后果，而不仅仅是“是什么”。</li>
                            </ul>
                        </li>
                        <li class="quote">“度过平台期后，你会享受读论文的快乐，因为它让你很好地了解你生活中用的这些AI工具的原理。”</li>
                    </ul>
                </div>
            </div>

            <button type="button" class="collapsible">
                <span>对“人”与“文化”的洞察</span>
                <span class="arrow">▶</span>
            </button>
            <div class="content">
                <div class="content-inner">
                    <ul>
                        <li><span class="opinion">AI发展是人的故事，而非纯粹的技术演进。</span>他详细梳理了关键人物间的合作与流动。</li>
                        <li><span class="opinion">不同研究文化并存：</span>他对比了以DeepMind为代表的欧洲学术圈（偏算法）和以Google Brain为代表的硅谷工业界（偏工程）的不同理念。</li>
                        <li><span class="fact">全栈“Builder”是未来趋势：</span>他认为未来AI行业会模糊岗位分工，需要更多能端到端解决问题的全栈人才。</li>
                        <li><span class="opinion">顶尖研究员的特质：</span>一类擅长解决难题，另一类更稀缺，擅长<span class="highlight">“找到这个时代最重要的问题是什么”</span>。</li>
                    </ul>
                </div>
            </div>

            <button type="button" class="collapsible">
                <span>战略性思考与未来展望</span>
                <span class="arrow">▶</span>
            </button>
            <div class="content">
                <div class="content-inner">
                    <ul>
                        <li>
                            <span class="fact">核心战略：“等待是有意义的”</span>
                            <p class="opinion">深刻理解模型的能力边界和发展节奏后，就可以判断哪些问题是暂时的技术局限。与其投入巨大工程资源去弥补，不如战略性地等待下一代模型自然解决。这是一种基于深刻理解的“积极的无为”。</p>
                        </li>
                        <li><span class="opinion">对Scaling Law持乐观态度</span>，认为在数据、算法和算力利用率上仍有巨大潜力可挖，远未到头。</li>
                        <li><span class="opinion">对行业巨头的分析：</span>Google人才储备和工程能力依然强大；OpenAI的战略更像是<span class="highlight">“在做一个下一代操作系统”</span>，叙事更为宏大。</li>
                    </ul>
                </div>
            </div>
            
            <button type="button" class="collapsible">
                <span>哲学层面的思考</span>
                <span class="arrow">▶</span>
            </button>
            <div class="content">
                 <div class="content-inner">
                    <ul>
                        <li>
                            <span class="fact">“惨痛的教训” (The Bitter Lesson)</span>
                            <p class="opinion">这是他反复引用的核心哲学。其观点是：长期来看，能够随算力增长而持续扩展的<span class="highlight">通用方法（如搜索和学习）</span>，终将战胜依赖人类先验知识的<span class="highlight">手工特征方法</span>。</p>
                        </li>
                         <li class="quote">“我们需要的是像我们一样有能力发现的人工智能体，而非装载了我们已有发现的智能体。”</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>

    <!-- ====== Part 2: Interactive Timelines ====== -->
    <div class="theme-section" id="paradigm-section">
        <h2>AI 发展史：模型范式的变迁</h2>
        <div class="timeline-wrapper">
            <div class="timeline" id="timeline-paradigm"></div>
        </div>
    </div>

    <div class="theme-section" id="infra-section">
        <h2>AI 发展史：基础设施与数据的变迁</h2>
        <div class="timeline-wrapper">
            <div class="timeline" id="timeline-infra"></div>
        </div>
    </div>
    
    <div class="theme-section" id="llm-section">
        <h2>AI 发展史：语言模型的发展脉络</h2>
        <div class="timeline-wrapper">
            <div class="timeline" id="timeline-llm"></div>
        </div>
    </div>

    <div class="theme-section" id="multimodal-section">
        <h2>AI 发展史：多模态模型的发展</h2>
        <div class="timeline-wrapper">
            <div class="timeline" id="timeline-multimodal"></div>
        </div>
    </div>
</div>


<!-- The Modal (shared by all parts) -->
<div id="timelineModal" class="modal">
  <div class="modal-content">
    <span class="close-btn">&times;</span>
    <h2 id="modal-year"></h2>
    <h3 id="modal-title"></h3>
    <div id="modal-tags"></div>
    <div id="modal-body" class="modal-body">
        <h4>历史背景</h4>
        <p id="modal-background"></p>
        <h4>核心贡献与意义</h4>
        <p id="modal-contribution"></p>
    </div>
  </div>
</div>

<script>
// --- Script for Part 1: Insights Collapsibles ---
const collapsibles = document.getElementsByClassName("collapsible");
for (let i = 0; i < collapsibles.length; i++) {
    collapsibles[i].addEventListener("click", function() {
        this.classList.toggle("active");
        const arrow = this.querySelector('.arrow');
        arrow.innerHTML = this.classList.contains("active") ? "▼" : "▶";
        
        const content = this.nextElementSibling;
        content.style.maxHeight = content.style.maxHeight ? null : content.scrollHeight + "px";
    });
}


// --- Script for Part 2: Interactive Timelines ---
const tagDetails = {
    "范式变革": { color: "#e74c3c" },
    "基础设施/工程": { color: "#8e44ad" },
    "模型架构": { color: "#2980b9" },
    "数据集/数据方法": { color: "#f39c12" },
    "生成式AI": { color: "#27ae60" },
    "对齐/Agent": { color: "#d35400" },
};

const allData = {
    paradigm: [
        { year: "2004", title: "Brook for GPUs", summary: "开启GPU通用计算之门。", background: "GPU的并行计算能力远超CPU，但编程极其困难，仅限于图形渲染专家。", contribution: "首次将GPU从专用图形硬件抽象为通用的、可用高级语言编程的并行计算单元。这一工作为后来利用GPU进行科学计算和深度学习奠定了至关重要的算力基础。", tags: ["基础设施/工程"] },
        { year: "2012", title: "AlexNet", summary: "深度学习的“开端之作”。", background: "在ImageNet竞赛中，传统基于手工特征提取的计算机视觉方法已达到瓶颈。", contribution: "首次同时扩展了数据、计算量（大规模使用GPU）和模型规模，证明了深度卷积神经网络在复杂任务上的巨大潜力，点燃了现代AI的革命之火。", tags: ["模型架构"] },
        { year: "2014", title: "Seq2Seq & Attention", summary: "引入注意力机制，变革NLP。", background: "RNN模型难以处理长度可变的输入输出序列（如翻译），并且在处理长序列时会遗忘早期的信息。", contribution: "提出了Encoder-Decoder架构和开创性的注意力（Attention）机制，允许模型动态关注输入的不同部分，极大提升了长序列任务的性能，并为Transformer铺平了道路。", tags: ["范式变革", "模型架构"] },
        { year: "2015", title: "ResNet (残差网络)", summary: "让训练千层网络成为可能。", background: "理论上更深的网络应该更强大，但实践中深度网络会遭遇梯度消失和性能退化的问题。", contribution: "引入了“残差连接”，让网络学习输入的增量变化而非完整的输出。这一简单而深刻的改动，彻底解决了深度网络的训练难题，至今仍是几乎所有主流AI模型的基本组件。", tags: ["模型架构"] },
        { year: "2017", title: "Transformer", summary: "“Attention Is All You Need”", background: "主流的RNN模型受其序列化计算的限制，难以并行，训练效率低下。", contribution: "彻底抛弃了RNN的循环结构，完全依赖自注意力机制来捕捉序列中的长距离依赖。其高度并行的特性完美适配GPU，“抽中了硬件彩票”，成为至今为止整个AI领域最核心的模型架构。", tags: ["范式变革", "模型架构"] },
        { year: "2017", title: "AlphaGo Zero", summary: "纯强化学习的胜利。", background: "之前的AlphaGo版本仍需要学习大量人类专家的棋谱数据。", contribution: "证明了纯粹的强化学习（从零开始自我对弈）可以达到甚至超越依赖人类知识的水平。其在推理时进行大量搜索（思考）的模式，也启发了后续大模型的“思维链”等能力。", tags: ["对齐/Agent"] },
        { year: "2017", title: "MOE (混合专家模型)", summary: "更大容量，更低成本。", background: "如何在获得超大模型容量的同时，降低推理时的计算成本。", contribution: "通过稀疏激活的“专家网络”结构，实现了在总参数量提升千倍的同时，推理成本几乎不变。此架构被GPT-4和DeepSeek等前沿模型采用。", tags: ["模型架构"] },
        { year: "2021", title: "LoRA", summary: "高效微调大模型的利器。", background: "对大模型进行全量微调成本高昂，且每个任务都需要存储一个完整的模型副本。", contribution: "提出低秩适应（Low-Rank Adaptation）方法，通过训练极少量的附加参数，达到接近全量微调的效果，极大地降低了模型定制化的门槛和成本。", tags: ["基础设施/工程"] },
        { year: "2022", title: "Chain of Thought (CoT)", summary: "让模型“一步一步思考”。", background: "即使是GPT-3这样的大模型，在处理需要多步推理的数学或逻辑问题时也常常出错。", contribution: "发现只需在提示中引导模型展示推理过程，就能解锁其内在的推理潜力，显著提升其在复杂问题上的表现，开启了Prompt Engineering的新纪元。", tags: ["对齐/Agent"] },
        { year: "2022", title: "ReAct", summary: "思考+行动，Agent的基石。", background: "模型虽然能推理（CoT），但与现实世界脱节，无法交互和获取新信息。", contribution: "提出了一个框架，让模型交错地进行推理（Thought）和行动（Action，如调用工具），并将行动结果作为新的观察来指导下一步思考，这是构建现代AI Agent的基础。", tags: ["对齐/Agent", "范式变革"] }
    ],
    infra: [
        { year: "2019", title: "ZeRO & DeepSpeed", summary: "突破单卡显存瓶颈。", background: "模型参数量增长速度远超单张GPU的显存容量，训练千亿参数模型成为巨大挑战。", contribution: "微软提出ZeRO（零冗余优化器），通过一种优化的数据并行框架，将模型状态切分到整个GPU集群中。该技术通过开源框架DeepSpeed实现，使得训练万亿级模型成为可能。", tags: ["基础设施/工程"] },
        { year: "2020", title: "Scaling Laws", summary: "让大模型训练成为科学。", background: "如何科学地、可预测地投入资源来训练大模型是一个关键问题。", contribution: "OpenAI通过大量实验，首次量化了大模型的扩展规律，即模型性能会随着计算量、模型大小、数据量的增加而成幂律下降。这为后续所有大模型研发提供了理论指导。", tags: ["基础设施/工程"] },
        { year: "2021", title: "LAION-5B", summary: "开源社区的力量。", background: "OpenAI发布了强大的CLIP模型但未开源其包含4亿图文对的训练数据集。", contribution: "一个由德国高中教师领导的开源社区，构建并开源了包含50亿图文对的多模态数据集。它成为Stable Diffusion等模型的基石，有力地推动了AIGC的开源生态。", tags: ["数据集/数据方法"] },
        { year: "2022", title: "Chinchilla", summary: "重新定义资源分配法则。", background: "OpenAI的Scaling Laws倾向于优先扩大模型参数。", contribution: "DeepMind的研究发现，在给定计算预算下，模型参数和训练数据量应等比例扩展，才能达到最优性能。这个“Chinchilla法则”修正了社区对资源分配的认知。", tags: ["基础设施/工程"] },
        { year: "2023", title: "RefinedWeb", summary: "从互联网中淘金。", background: "高质量的预训练语料库被少数大公司垄断，成为开源社区发展的障碍。", contribution: "证明了仅通过对公开的互联网数据进行精细的过滤和去重，就可以得到一个高质量的大规模数据集，其训练效果不亚于甚至超过精心策划的人工数据集。", tags: ["数据集/数据方法"] },
        { year: "2024", title: "Megascale", summary: "万卡集群的稳定训练。", background: "在万卡级别的集群上进行长时间稳定训练，面临着硬件故障频发和效率低下的巨大挑战。", contribution: "Meta分享了其在万卡规模集群上训练大模型的工程经验，建立了一套深度可观察的系统，能够自动诊断、定位和恢复故障，是超大规模AI计算的工程实践典范。", tags: ["基础设施/工程"] }
    ],
    llm: [
        { year: "2013", title: "Word2Vec", summary: "赋予词语向量生命。", background: "传统NLP将单词视为孤立的符号，无法捕捉其深层含义。", contribution: "开创性地使用神经网络学习单词的分布式向量表示（词嵌入），使得词语的语义关系可以在向量空间中进行代数运算，是现代NLP技术的基石。", tags: ["模型架构"] },
        { year: "2016", title: "Google's NMT", summary: "神经网络翻译的工业化。", background: "学术界的神经网络翻译模型在生产环境中的性能和效率不如传统的统计机器翻译。", contribution: "Google将学术界的最新成果工程化，构建了首个生产级的神经网络翻译系统（Google Translate），实现了工业界翻译范式的转移。", tags: ["基础设施/工程"] },
        { year: "2018", title: "GPT-1", summary: "生成式预训练的开端。", background: "NLP领域缺乏像CV领域那样通用的预训练+微调范式。", contribution: "提出了“无监督预训练 + 监督微调”的新范式，并采用了至今仍在使用的Decoder-only架构和Next Token Prediction训练目标。", tags: ["范式变革", "模型架构"] },
        { year: "2018", title: "BERT", summary: "双向理解，统治NLP数年。", background: "GPT-1是单向的，无法同时利用一个词左右两边的上下文信息。", contribution: "提出了“完形填空”（Masked Language Model）预训练任务，使得模型可以进行深度双向表示学习。BERT在各项NLP基准上大幅超越了GPT-1，成为当时的主导范式。", tags: ["模型架构"] },
        { year: "2019", title: "GPT-2", summary: "规模化涌现零样本能力。", background: "在BERT的阴影下，OpenAI坚持GPT路线，并相信扩大规模能带来质变。", contribution: "将模型规模和数据量扩大了一个数量级，结果模型涌现出了在没有经过专门训练的情况下完成多种任务的能力，有力地证明了“规模化”是通往通用智能的关键路径。", tags: ["模型架构"] },
        { year: "2020", title: "GPT-3", summary: "催生“提示工程”的巨兽。", background: "GPT-2证明了规模化的潜力，OpenAI决定进行一次史无前例的规模扩张。", contribution: "模型规模再次扩大100倍（1750亿参数），展现出强大的“上下文学习”（In-context Learning）能力。这彻底改变了人机交互的范式，开启了Prompt Engineering的时代。", tags: ["范式变革", "模型架构"] },
        { year: "2022", title: "InstructGPT", summary: "对齐人类意图的“前奏”。", background: "GPT-3等预训练模型虽然强大，但并不可控，常常“答非所问”或生成有害内容。", contribution: "开创性地提出了基于人类反馈的强化学习（RLHF）流程，来“对齐”模型，使其输出更符合人类的指令和期望。这是ChatGPT能够成为现象级产品的核心技术。", tags: ["对齐/Agent", "范式变革"] },
        { year: "2024", title: "Tulu 3", summary: "开源后训练的典范。", background: "大模型的后训练（Post-training）过程，如SFT和DPO，通常是闭源的，是模型能力的关键“秘方”。", contribution: "Allen AI开源了其完整的后训练流程、数据和代码，展示了如何基于开源基座模型（Llama 3.1）通过精心后训练，达到与顶尖闭源模型相媲美的性能。", tags: ["基础设施/工程"] }
    ],
    multimodal: [
        { year: "2014", title: "Deep Video", summary: "深度学习进军视频领域。", background: "在AlexNet证明了深度学习在图像上的成功后，研究者开始探索其在视频理解上的应用。", contribution: "由李飞飞团队领导，首次将深度学习应用于大规模视频分类，并构建了当时最大的视频数据集，是多模态学习的早期探索。", tags: ["数据集/数据方法"] },
        { year: "2014", title: "双流网络", summary: "视频理解的“AlexNet时刻”。", background: "早期的视频模型仅处理静态帧，对动作和运动的理解能力很弱。", contribution: "创造性地使用两个并行的卷积网络流，一个处理空间信息（单帧图像），另一个处理时间信息（光流），首次在视频分类任务上超越了传统手工特征方法。", tags: ["模型架构"] },
        { year: "2015", title: "Diffusion Models", summary: "扩散模型的首次提出。", background: "GAN训练不稳定，VAE生成图像模糊，需要更稳定且高质量的生成范式。", contribution: "受物理学扩散过程启发，首次提出了通过逐步加噪再学习逆向去噪的生成模型框架。虽然早期效果不佳被忽视，但为5年后的复兴埋下了伏笔。", tags: ["生成式AI", "模型架构"] },
        { year: "2020", title: "ViT (视觉Transformer)", summary: "让Transformer“看见”世界。", background: "CNN主导着计算机视觉领域，而Transformer则在NLP领域大放异彩。", contribution: "提出一种简单而有效的方法：将图像分割成图块（Patches）并序列化，直接输入给标准的Transformer。证明了只要数据量足够大，纯Transformer架构在视觉任务上也能超越CNN。", tags: ["范式变革", "模型架构"] },
        { year: "2020", title: "DDPM (扩散模型复兴)", summary: "让扩散模型重回舞台中央。", background: "2015年提出的扩散模型因效果差、速度慢而被冷落。", contribution: "通过简化训练目标（预测噪声）和改进网络结构，让扩散模型一跃成为与GAN并驾齐驱甚至更优的SOTA生成模型，且训练稳定。", tags: ["生成式AI", "模型架构"] },
        { year: "2021", title: "CLIP", summary: "打通文本与图像的“任督二脉”。", background: "传统的视觉模型依赖昂贵的人工标注，且无法理解开放世界的概念。", contribution: "在大规模图文对数据上进行对比学习，成功地将视觉和语言两个模态映射到一个统一的表示空间。这是所有现代文生图技术的关键基础。", tags: ["生成式AI", "范式变革"] },
        { year: "2021", title: "Stable Diffusion", summary: "高效普及的文生图模型。", background: "扩散模型在像素空间直接计算，资源消耗巨大，难以在消费级硬件上运行。", contribution: "创造性地提出在低维的潜空间（Latent Space）中执行扩散过程，极大地降低了计算成本，并结合CLIP实现了精准的文本控制。其开源引爆了AIGC社区。", tags: ["生成式AI", "模型架构"] },
        { year: "2022", title: "DiT (扩散Transformer)", summary: "Sora的技术基石。", background: "扩散模型普遍使用的U-Net架构在扩展性上不如Transformer。", contribution: "成功将Transformer作为扩散模型的骨干网络，统一了生成模型的架构，并带来了更强的可扩展性。这项工作是OpenAI Sora等顶级视频生成模型的技术基础。", tags: ["生成式AI", "模型架构", "基础设施/工程"] }
    ]
};

function buildTimeline(containerId, data) {
    const timeline = document.getElementById(containerId);
    if (!timeline) return;

    data.forEach(item => {
        const itemDiv = document.createElement('div');
        itemDiv.className = 'timeline-item';

        let tagsHTML = '';
        if (item.tags) {
            item.tags.forEach(tagName => {
                const tagInfo = tagDetails[tagName.trim()];
                if (tagInfo) {
                    tagsHTML += `<span class="timeline-tag" style="background-color: ${tagInfo.color};">${tagName}</span>`;
                }
            });
        }

        itemDiv.innerHTML = `
            <div class="timeline-dot"></div>
            <div class="timeline-content">
                <div class="timeline-date">${item.year}</div>
                <h3 class="timeline-title">${item.title}</h3>
            </div>
        `;
        
        itemDiv.querySelector('.timeline-content').addEventListener('click', () => {
            document.getElementById('modal-year').innerText = item.year;
            document.getElementById('modal-title').innerText = item.title;
            document.getElementById('modal-background').innerText = item.background;
            document.getElementById('modal-contribution').innerText = item.contribution;
            document.getElementById('modal-tags').innerHTML = tagsHTML;
            document.getElementById('timelineModal').style.display = 'block';
        });

        timeline.appendChild(itemDiv);
    });
}

document.addEventListener('DOMContentLoaded', () => {
    buildTimeline('timeline-paradigm', allData.paradigm);
    buildTimeline('timeline-infra', allData.infra);
    buildTimeline('timeline-llm', allData.llm);
    buildTimeline('timeline-multimodal', allData.multimodal);

    const modal = document.getElementById('timelineModal');
    const closeBtn = document.querySelector('.close-btn');

    closeBtn.onclick = function() {
        modal.style.display = "none";
    }
    window.onclick = function(event) {
        if (event.target == modal) {
            modal.style.display = "none";
        }
    }
});
</script>

</body>
</html>